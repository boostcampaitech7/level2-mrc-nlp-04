{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer, TrainingArguments,\n",
    "    BertModel, BertPreTrainedModel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self,\n",
    "        config\n",
    "    ):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 ~ 1.0 사이 값으로 scaling\n",
    "def min_max_scaling(scores):\n",
    "    min_score = torch.min(scores)\n",
    "    max_score = torch.max(scores)\n",
    "    scaled_scores = (scores - min_score) / (max_score - min_score)\n",
    "    return scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k 확인\n",
    "def get_relevant_doc(\n",
    "        tokenizer,\n",
    "        query,\n",
    "        passage,\n",
    "        ground_truth,\n",
    "        p_name,\n",
    "        q_name,\n",
    "        topk=1,\n",
    "        args=None\n",
    "    ): # 유사도 높은 context 및 ground-truth context와의 유사도 추출\n",
    "    \n",
    "    with open(\"../code/retrieval/dense_encoder/\" + p_name,  \"rb\") as f:\n",
    "        p_encoder = pickle.load(f)\n",
    "    with open(\"../code/retrieval/dense_encoder/\" + q_name, \"rb\") as f:\n",
    "        q_encoder = pickle.load(f)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p_encoder.eval()\n",
    "        q_encoder.eval()\n",
    "        q_seps = tokenizer([query], padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "        q_emb = q_encoder(**q_seps).to(\"cpu\") # (num_query, emb_dim)\n",
    "\n",
    "        ground_truth = tokenizer(ground_truth, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "        g_emb = p_encoder(**ground_truth).to(\"cpu\")\n",
    "\n",
    "        p_embs = []\n",
    "        for p in passage:\n",
    "            p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "            p_emb = p_encoder(**p).to(\"cpu\").numpy()\n",
    "            p_embs.append(p_emb)\n",
    "    \n",
    "    p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "    dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1)) # question과의 유사도\n",
    "    rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "\n",
    "    # ground_truth와 passages의 유사도\n",
    "    p_embs = F.normalize(p_embs, dim=-1)\n",
    "    g_emb = F.normalize(g_emb, dim=-1)\n",
    "    dot_prod_scores = torch.matmul(\n",
    "        g_emb, torch.transpose(p_embs, 0, 1)).squeeze() # 각 문서간의 유사도\n",
    "    # softmax = F.softmax(dot_prod_scores, dim=1).squeeze() # (num_passage,) → ground-truth 문서에 대한 전체 유사도\n",
    "    dot_prod_scores = min_max_scaling(dot_prod_scores)\n",
    "\n",
    "    return dot_prod_scores, rank[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document search\n",
    "def search_doc(tokenizer, query, contexts, p_name, q_name, topk): # query가 여럿일 경우 순서대로 검색\n",
    "    context_score = []\n",
    "\n",
    "    # for q in query\n",
    "    for i, q in tqdm(enumerate(query), total=len(query), desc=\"Searching\", unit=\"query\"):\n",
    "        score, indices = get_relevant_doc(\n",
    "            tokenizer=tokenizer, query=q, passage=contexts, ground_truth=contexts[i], p_name=p_name, q_name=q_name, topk=topk)\n",
    "\n",
    "        # print(f\"[Search Query] {q}\")\n",
    "        # print(f'score : {scores}')\n",
    "\n",
    "        arr = [[contexts[idx], score[idx]] for idx in indices] \n",
    "        context_score.append(arr) # [context, score]\n",
    "\n",
    "    return context_score # (num_query, k, 2)  query마다 top-k개의 context와 score로 구성된 리스트 반환\n",
    "\n",
    "        # top-k 문서 및 유사도 확인\n",
    "        # for rank, idx in enumerate(indices):\n",
    "        #     print(f\"Top-{rank + 1}th Passage (Index {idx})\")\n",
    "        #     # pprint(retriever.passage['context'][idx])\n",
    "        #     print(f\"유사도 : {score[idx]}\")\n",
    "        #     pprint(contexts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Searching: 100%|██████████| 240/240 [16:24<00:00,  4.10s/query]\n"
     ]
    }
   ],
   "source": [
    "# wikipedia 불러오기\n",
    "# with open(\"../data/wikipedia_documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     wiki = json.load(f)\n",
    "# contexts = list(dict.fromkeys([\n",
    "#             value[\"text\"] for value in wiki.values()\n",
    "#         ]))\n",
    "\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "p_name = \"p_korquad_1.bin\"\n",
    "q_name = \"q_korquad_1.bin\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "dataset = load_from_disk(\"../data/train_dataset\")\n",
    "val_dataset = dataset[\"validation\"][\"question\"]\n",
    "contexts = dataset[\"validation\"][\"context\"]\n",
    "\n",
    "# query와 비교하여 문서 찾기\n",
    "query = val_dataset\n",
    "\n",
    "context_score = search_doc(tokenizer, query, contexts, p_name, q_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_score = np.array(context_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_see(k):\n",
    "    correct_ids = []\n",
    "    wrong_ids = []\n",
    "\n",
    "    for con_sco in context_score:\n",
    "        for idx in range(k):\n",
    "            context, score = con_sco[idx]\n",
    "            score = re.sub(\n",
    "                \"[A-Za-z()]\",\n",
    "                \"\",\n",
    "                score\n",
    "                )\n",
    "            if float(score) >= 0.99:\n",
    "                correct_ids.append(context)\n",
    "                break\n",
    "        else:\n",
    "            wrong_ids.append(context)\n",
    "\n",
    "    print(f\"전체 개수: {len(context_score)}, 정답 개수: {len(correct_ids)}, 오답 개수: {len(wrong_ids)}, 정답률: {len(correct_ids)/len(context_score):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 개수: 240, 정답 개수: 237, 오답 개수: 3, 정답률: 98.7500%\n"
     ]
    }
   ],
   "source": [
    "top_k_see(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset\n",
    "epoch: 3, lr: 5e-5, batch: 8, weight_decay: 0.01, top-k: 20\n",
    "전체 개수: 240, 정답 개수: 221, 오답 개수: 19, 정답률: 92.0833%\n",
    "\n",
    "train_dataset + korquad v1.0 (context 당 question 랜덤 하나만 추출)\n",
    "epoch: 2, lr: 4e-5, batch: 5, weight_decay: 0.01, top-k: 5\n",
    "전체 개수: 240, 정답 개수: 211, 오답 개수: 29, 정답률: 87.9167%\n",
    "\n",
    "epoch: 2, lr: 4e-5, batch: 5, weight_decay: 0.01, top-k: 20\n",
    "전체 개수: 240, 정답 개수: 231, 오답 개수: 9, 정답률: 96.2500%\n",
    "\n",
    "epoch: 2, lr: 4e-5, batch: 5, weight_decay: 0.01, top-k: 40\n",
    "전체 개수: 240, 정답 개수: 236, 오답 개수: 4, 정답률: 98.3333%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
