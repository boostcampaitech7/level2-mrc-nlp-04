{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리트리버 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\\\n\", \" \", text)\n",
    "    text = re.sub(r\"#\", \" \", text)\n",
    "    text = re.sub(\n",
    "        r\"[^A-Za-z0-9가-힣.?!,()~‘’“”\" \":%&《》〈〉''㈜·\\-'+\\s一-龥サマーン]\",\n",
    "        \"\",\n",
    "        text,\n",
    "    )  # サマーン 는 predictions.json에 있었음\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 두 개 이상의 연속된 공백을 하나로 치환\n",
    "    # text = re.sub(r\"[^A-Za-z0-9가-힣.?!,()~‘’“”\"\":%&《》〈〉''㈜·\\-\\'+\\s一-龥]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def evaluate_retriever(df, topk=100, is_preprocess=False, is_title=False):\n",
    "    df[\"context\"] = df[\"context\"].apply(\n",
    "        lambda x: ast.literal_eval(x)\n",
    "    )\n",
    "    correct_ids = []\n",
    "    wrong_ids = []\n",
    "    for idx,row in df.iterrows():\n",
    "        org_context = (\n",
    "            preprocess(row[\"original_context\"])\n",
    "            if is_preprocess\n",
    "            else row[\"original_context\"]\n",
    "        )\n",
    "        if is_title:\n",
    "            for passage in row[\"context\"][:topk]:\n",
    "                if passage.split(\": \")[1] == org_context:\n",
    "                    correct_ids.append(row[\"id\"])\n",
    "                    break\n",
    "            else:\n",
    "                wrong_ids.append(row[\"id\"])\n",
    "        else:\n",
    "            if org_context in row[\"context\"][:topk]:\n",
    "                correct_ids.append(row[\"id\"])\n",
    "            else:\n",
    "                wrong_ids.append(row[\"id\"])\n",
    "\n",
    "    print(\n",
    "        f\"전체: {len(df)}, 맞은 개수: {len(correct_ids)}, 틀린 개수: {len(wrong_ids)}, 정답률: {(len(correct_ids)/len(df)):.4%}\"\n",
    "    )\n",
    "    return correct_ids, wrong_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_path = os.path.join(parent_dir, \"data\", \"es_train\")\n",
    "df_es_100 = pd.read_csv(os.path.join(es_path, \"train_es_100.csv\"))\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    dfs.append(deepcopy(df_es_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 227, 틀린 개수: 13, 정답률: 94.5833%\n",
      "전체: 240, 맞은 개수: 231, 틀린 개수: 9, 정답률: 96.2500%\n",
      "전체: 240, 맞은 개수: 232, 틀린 개수: 8, 정답률: 96.6667%\n",
      "전체: 240, 맞은 개수: 232, 틀린 개수: 8, 정답률: 96.6667%\n",
      "전체: 240, 맞은 개수: 234, 틀린 개수: 6, 정답률: 97.5000%\n",
      "전체: 240, 맞은 개수: 234, 틀린 개수: 6, 정답률: 97.5000%\n",
      "전체: 240, 맞은 개수: 234, 틀린 개수: 6, 정답률: 97.5000%\n",
      "전체: 240, 맞은 개수: 235, 틀린 개수: 5, 정답률: 97.9167%\n",
      "전체: 240, 맞은 개수: 235, 틀린 개수: 5, 정답률: 97.9167%\n"
     ]
    }
   ],
   "source": [
    "for df, topk in zip(deepcopy(dfs), [k for k in range(10, 110, 10)]):\n",
    "    _, _ = evaluate_retriever(df, topk=topk, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_path = os.path.join(parent_dir, \"data\", \"bm25_train\")\n",
    "\n",
    "df_bm25_100 = pd.read_csv(os.path.join(bm25_path, \"train_bm25_100.csv\"))\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    dfs.append(deepcopy(df_bm25_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 203, 틀린 개수: 37, 정답률: 84.5833%\n",
      "전체: 240, 맞은 개수: 210, 틀린 개수: 30, 정답률: 87.5000%\n",
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n",
      "전체: 240, 맞은 개수: 216, 틀린 개수: 24, 정답률: 90.0000%\n",
      "전체: 240, 맞은 개수: 217, 틀린 개수: 23, 정답률: 90.4167%\n",
      "전체: 240, 맞은 개수: 217, 틀린 개수: 23, 정답률: 90.4167%\n",
      "전체: 240, 맞은 개수: 217, 틀린 개수: 23, 정답률: 90.4167%\n",
      "전체: 240, 맞은 개수: 217, 틀린 개수: 23, 정답률: 90.4167%\n",
      "전체: 240, 맞은 개수: 218, 틀린 개수: 22, 정답률: 90.8333%\n",
      "전체: 240, 맞은 개수: 218, 틀린 개수: 22, 정답률: 90.8333%\n"
     ]
    }
   ],
   "source": [
    "for df, topk in zip(deepcopy(dfs), [k for k in range(10, 110, 10)]):\n",
    "    _, _ = evaluate_retriever(df, topk=topk, is_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank-Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_path = os.path.join(parent_dir, \"data\", \"es_train\")\n",
    "\n",
    "df_es_20 = pd.read_csv(os.path.join(es_path, \"not_train_es_20_rerank_5.csv\"))\n",
    "df_es_30 = pd.read_csv(os.path.join(es_path, \"not_train_es_30_rerank_5.csv\"))\n",
    "df_es_40 = pd.read_csv(os.path.join(es_path, \"not_train_es_40_rerank_5.csv\"))\n",
    "df_es_50 = pd.read_csv(os.path.join(es_path, \"not_train_es_50_rerank_5.csv\"))\n",
    "df_es_60 = pd.read_csv(os.path.join(es_path, \"not_train_es_60_rerank_5.csv\"))\n",
    "df_es_70 = pd.read_csv(os.path.join(es_path, \"not_train_es_70_rerank_5.csv\"))\n",
    "df_es_80 = pd.read_csv(os.path.join(es_path, \"not_train_es_80_rerank_5.csv\"))\n",
    "df_es_90 = pd.read_csv(os.path.join(es_path, \"not_train_es_90_rerank_5.csv\"))\n",
    "df_es_100 = pd.read_csv(os.path.join(es_path, \"not_train_es_100_rerank_5.csv\"))\n",
    "\n",
    "dfs = [\n",
    "    df_es_20,\n",
    "    df_es_30,\n",
    "    df_es_40,\n",
    "    df_es_50,\n",
    "    df_es_60,\n",
    "    df_es_70,\n",
    "    df_es_80,\n",
    "    df_es_90,\n",
    "    df_es_100,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n",
      "전체: 240, 맞은 개수: 223, 틀린 개수: 17, 정답률: 92.9167%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 224, 틀린 개수: 16, 정답률: 93.3333%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n",
      "전체: 240, 맞은 개수: 222, 틀린 개수: 18, 정답률: 92.5000%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=5, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 218, 틀린 개수: 22, 정답률: 90.8333%\n",
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n",
      "전체: 240, 맞은 개수: 221, 틀린 개수: 19, 정답률: 92.0833%\n",
      "전체: 240, 맞은 개수: 219, 틀린 개수: 21, 정답률: 91.2500%\n",
      "전체: 240, 맞은 개수: 221, 틀린 개수: 19, 정답률: 92.0833%\n",
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n",
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n",
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n",
      "전체: 240, 맞은 개수: 220, 틀린 개수: 20, 정답률: 91.6667%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=4, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n",
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n",
      "전체: 240, 맞은 개수: 214, 틀린 개수: 26, 정답률: 89.1667%\n",
      "전체: 240, 맞은 개수: 214, 틀린 개수: 26, 정답률: 89.1667%\n",
      "전체: 240, 맞은 개수: 216, 틀린 개수: 24, 정답률: 90.0000%\n",
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n",
      "전체: 240, 맞은 개수: 214, 틀린 개수: 26, 정답률: 89.1667%\n",
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n",
      "전체: 240, 맞은 개수: 215, 틀린 개수: 25, 정답률: 89.5833%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=3, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 206, 틀린 개수: 34, 정답률: 85.8333%\n",
      "전체: 240, 맞은 개수: 209, 틀린 개수: 31, 정답률: 87.0833%\n",
      "전체: 240, 맞은 개수: 209, 틀린 개수: 31, 정답률: 87.0833%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 210, 틀린 개수: 30, 정답률: 87.5000%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 207, 틀린 개수: 33, 정답률: 86.2500%\n",
      "전체: 240, 맞은 개수: 207, 틀린 개수: 33, 정답률: 86.2500%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=2, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 190, 틀린 개수: 50, 정답률: 79.1667%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n",
      "전체: 240, 맞은 개수: 191, 틀린 개수: 49, 정답률: 79.5833%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=1, is_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank-BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_path = os.path.join(parent_dir, \"data\", \"bm25_train\")\n",
    "\n",
    "df_bm25_20 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_20_rerank_5.csv\"))\n",
    "df_bm25_30 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_30_rerank_5.csv\"))\n",
    "df_bm25_40 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_40_rerank_5.csv\"))\n",
    "df_bm25_50 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_50_rerank_5.csv\"))\n",
    "df_bm25_60 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_60_rerank_5.csv\"))\n",
    "df_bm25_70 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_70_rerank_5.csv\"))\n",
    "df_bm25_80 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_80_rerank_5.csv\"))\n",
    "df_bm25_90 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_90_rerank_5.csv\"))\n",
    "df_bm25_100 = pd.read_csv(os.path.join(bm25_path, \"not_train_bm25_100_rerank_5.csv\"))\n",
    "\n",
    "dfs = [\n",
    "    df_bm25_20,\n",
    "    df_bm25_30,\n",
    "    df_bm25_40,\n",
    "    df_bm25_50,\n",
    "    df_bm25_60,\n",
    "    df_bm25_70,\n",
    "    df_bm25_80,\n",
    "    df_bm25_90,\n",
    "    df_bm25_100,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 205, 틀린 개수: 35, 정답률: 85.4167%\n",
      "전체: 240, 맞은 개수: 207, 틀린 개수: 33, 정답률: 86.2500%\n",
      "전체: 240, 맞은 개수: 207, 틀린 개수: 33, 정답률: 86.2500%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 208, 틀린 개수: 32, 정답률: 86.6667%\n",
      "전체: 240, 맞은 개수: 209, 틀린 개수: 31, 정답률: 87.0833%\n",
      "전체: 240, 맞은 개수: 209, 틀린 개수: 31, 정답률: 87.0833%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, is_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 204, 틀린 개수: 36, 정답률: 85.0000%\n",
      "전체: 240, 맞은 개수: 206, 틀린 개수: 34, 정답률: 85.8333%\n",
      "전체: 240, 맞은 개수: 205, 틀린 개수: 35, 정답률: 85.4167%\n",
      "전체: 240, 맞은 개수: 206, 틀린 개수: 34, 정답률: 85.8333%\n",
      "전체: 240, 맞은 개수: 206, 틀린 개수: 34, 정답률: 85.8333%\n",
      "전체: 240, 맞은 개수: 205, 틀린 개수: 35, 정답률: 85.4167%\n",
      "전체: 240, 맞은 개수: 204, 틀린 개수: 36, 정답률: 85.0000%\n",
      "전체: 240, 맞은 개수: 205, 틀린 개수: 35, 정답률: 85.4167%\n",
      "전체: 240, 맞은 개수: 205, 틀린 개수: 35, 정답률: 85.4167%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=4, is_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 203, 틀린 개수: 37, 정답률: 84.5833%\n",
      "전체: 240, 맞은 개수: 206, 틀린 개수: 34, 정답률: 85.8333%\n",
      "전체: 240, 맞은 개수: 203, 틀린 개수: 37, 정답률: 84.5833%\n",
      "전체: 240, 맞은 개수: 204, 틀린 개수: 36, 정답률: 85.0000%\n",
      "전체: 240, 맞은 개수: 204, 틀린 개수: 36, 정답률: 85.0000%\n",
      "전체: 240, 맞은 개수: 204, 틀린 개수: 36, 정답률: 85.0000%\n",
      "전체: 240, 맞은 개수: 203, 틀린 개수: 37, 정답률: 84.5833%\n",
      "전체: 240, 맞은 개수: 202, 틀린 개수: 38, 정답률: 84.1667%\n",
      "전체: 240, 맞은 개수: 202, 틀린 개수: 38, 정답률: 84.1667%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=3, is_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 195, 틀린 개수: 45, 정답률: 81.2500%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n",
      "전체: 240, 맞은 개수: 198, 틀린 개수: 42, 정답률: 82.5000%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n",
      "전체: 240, 맞은 개수: 196, 틀린 개수: 44, 정답률: 81.6667%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n",
      "전체: 240, 맞은 개수: 197, 틀린 개수: 43, 정답률: 82.0833%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=2, is_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체: 240, 맞은 개수: 171, 틀린 개수: 69, 정답률: 71.2500%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 175, 틀린 개수: 65, 정답률: 72.9167%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 174, 틀린 개수: 66, 정답률: 72.5000%\n",
      "전체: 240, 맞은 개수: 173, 틀린 개수: 67, 정답률: 72.0833%\n"
     ]
    }
   ],
   "source": [
    "for df in deepcopy(dfs):\n",
    "    _, _ = evaluate_retriever(df, topk=1, is_title=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
